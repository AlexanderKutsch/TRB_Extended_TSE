{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3135985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "import contextily as cx\n",
    "import datetime as dt\n",
    "import json\n",
    "import time\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from functions_file import *\n",
    "print(testfunction(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1f4099",
   "metadata": {},
   "source": [
    "### 1. Import (cleaned, per polygon, without parking removed) data and add basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d64548",
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons = pd.read_csv('../data/polygons11.csv') #polygons11\n",
    "file_type = 'pickle'\n",
    "polygon_names = polygons.name.values[polygons.name.values != 'polygon_r4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74713c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify values:\n",
    "speed_threshold = 1 #km/h\n",
    "min_mean_speed = 15 #km/h\n",
    "min_diff_between_timestamps = '3s' #has to be a string\n",
    "min_duration_of_stops = 5 #seconds\n",
    "vehicle_type_considered_for_stop = ['Bus','Taxi', 'Medium Vehicle', 'Heavy Vehicle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6d9c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "save = 'off'\n",
    "#run over all polygons\n",
    "for polygon_name in polygon_names:\n",
    "    file_name = '../output/data_clean/prepared_data_%s.pkl'%(polygon_name)\n",
    "    waypoints_w_dist_mode = import_clean_data(file_name,file_type,polygon_name)\n",
    "    \n",
    "    #assure that geometry is of type point\n",
    "    if type(waypoints_w_dist_mode.iloc[0]['geometry'])==str:\n",
    "        waypoints_w_dist_mode['geometry'] = waypoints_w_dist_mode['geometry'].apply(lambda x: Point([float(i) for i in x[7:-1].split()]))\n",
    "        waypoints_w_dist_mode = gpd.GeoDataFrame(waypoints_w_dist_mode, geometry=waypoints_w_dist_mode.geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "    #filter for speed < speed_threshold\n",
    "    data = waypoints_w_dist_mode[(waypoints_w_dist_mode.speed<speed_threshold)]\n",
    "    \n",
    "    #calculate mean speed for each timestep, merge the mean speed to each datapoint\n",
    "    mspd = pd.DataFrame(waypoints_w_dist_mode[waypoints_w_dist_mode['type'].isin(['Car'])]\n",
    "                        .groupby('timestamp')['speed'].mean()).reset_index().rename(columns={'speed':'mean_speed'})\n",
    "    data = data.join(mspd.set_index('timestamp'), on=data['timestamp'])\n",
    "    \n",
    "    #filter for vehicle types\n",
    "    spvec_stops = data[(data['type'].isin(vehicle_type_considered_for_stop))]\n",
    "\n",
    "    #filter for timesteps, where the mean speed > min_mean_speed\n",
    "    spvec_stops = spvec_stops[spvec_stops.mean_speed>min_mean_speed]\n",
    "\n",
    "    print('Vehicles stopping, when the mean speed of all vehicles was bigger than %s km/h: '%min_mean_speed, str(len(spvec_stops.unique_id.unique())))\n",
    "\n",
    "    # Calculate speed differences for every time step, calculate timestamp difference for all ids beneath the threshold\n",
    "    # Where the time diff is bigger than 'min_diff_between_timestamps' seconds, a new stop id is appended\n",
    "\n",
    "    spvec_stops['speed_diff'] = spvec_stops.groupby('unique_id')['speed'].diff()\n",
    "    spvec_stops['time_diff'] = spvec_stops.groupby('unique_id')['timestamp'].diff()\n",
    "    spvec_stops['td_val'] = spvec_stops['time_diff'] > min_diff_between_timestamps # min difference in consecutive timestamps to be counted as new stop\n",
    "    unique_stop_id = 0\n",
    "    stop_ids = []\n",
    "    for i,row in spvec_stops.iterrows():\n",
    "        if pd.isnull(row['time_diff']) or row['td_val']:\n",
    "            unique_stop_id += 1\n",
    "        stop_ids.append(unique_stop_id)\n",
    "    spvec_stops['stop_id'] = stop_ids\n",
    "\n",
    "    #calculate duration of stops, filter for minimum 'min duration of stop' second-stops\n",
    "    aggr = spvec_stops.groupby('stop_id').max('timestamp')\n",
    "    aggr['max_t'] = spvec_stops.groupby('stop_id')['timestamp'].max()\n",
    "    aggr['min_t'] = spvec_stops.groupby('stop_id')['timestamp'].min()\n",
    "    aggr['span_per_stop'] = (aggr['max_t']-aggr['min_t'])/np.timedelta64(1, 's')\n",
    "    aggr['type'] = spvec_stops.groupby('stop_id')['type'].apply(lambda x: list(np.unique(x))[0])\n",
    "    aggr = aggr[aggr.span_per_stop>min_duration_of_stops]     #min duration of stop\n",
    "    print('Number of stopped vehicles after filtering by min duration: %s'%len(aggr))\n",
    "    #aggr.sort_values(by='span_per_stop', ascending=False).head(5)\n",
    "\n",
    "    # load q,k,v data per interval (30 secs on rolling 3 minutes)\n",
    "    # add scaled up flows and densities\n",
    "    intervals_MS = pd.read_pickle('../output/data_processed/processed_data_all_bypolygon.pkl')\n",
    "    scalefactorsfile = '../output/data_processed/scalefactors_bypolygon.pkl'   \n",
    "    # to read\n",
    "    with open(scalefactorsfile, 'rb') as f:\n",
    "        scalefactors = pickle.load(f)\n",
    "    # scale values back up\n",
    "    cs = ['q_all_MS','k_all_MS','q_all_LD','k_all_LD']\n",
    "    for c in ['q_all_MS','k_all_MS','q_all_LD','k_all_LD']:\n",
    "        scaledup = scaleup(intervals_MS[c],intervals_MS['polygon'],scalefactors,c)\n",
    "        intervals_MS['%s_s'%c] = scaledup\n",
    "        cs.append('%s_s'%c)\n",
    "    intervals_MS['v2'] = intervals_MS.q_all_LD_s / intervals_MS.k_all_LD_s\n",
    "    \n",
    "    #add the stops to the intervals\n",
    "    start = time.time()\n",
    "    intervals_MS = intervals_MS[intervals_MS.polygon == polygon_name]\n",
    "    intervals_MS['stop_count'] = np.zeros(len(intervals_MS))\n",
    "    if len(aggr)>0:\n",
    "        intervals_MS['stop_type'] = ['']*len(intervals_MS)\n",
    "        intervals_MS['stop_length'] = ['']*len(intervals_MS)\n",
    "        stop_types = []\n",
    "        # add all columns that match the stops, vehicle type and duration to the intervals\n",
    "        for i,row in aggr.iterrows():\n",
    "            t_start_higher_tmin = row['min_t'] < (intervals_MS.times-pd.Timedelta('150s')) #1\n",
    "            t_start_lower_tmax = row['max_t'] > (intervals_MS.times - pd.Timedelta('150s')) #2\n",
    "            t_start_lower_tmin = row['min_t'] > (intervals_MS.times-pd.Timedelta('150s')) #3\n",
    "            t_end_higher_tmin = row['min_t'] < (intervals_MS.times+pd.Timedelta('30s')) #4\n",
    "            # if 1+2 or 3+4 is fulfilled, the stop happened within the current interval\n",
    "            true = (t_start_higher_tmin & t_start_lower_tmax) | (t_start_lower_tmin & t_end_higher_tmin)\n",
    "            # additionally add the vehicle type of that stop and the duration\n",
    "            intervals_MS.stop_count += true\n",
    "            intervals_MS['new_type'] = np.where(true, row.type, '')\n",
    "            intervals_MS.stop_type= intervals_MS[['stop_type','new_type']].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "            intervals_MS['new_length'] = np.where(true, row.span_per_stop, '')\n",
    "            intervals_MS.stop_length= intervals_MS[['new_length','stop_length']].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "        intervals_MS['veh_stop_types'] = intervals_MS.stop_type.str.split(',').apply(lambda x: list(filter(lambda num: num != '', x)))\n",
    "        intervals_MS['veh_stop_lengths'] = intervals_MS.stop_length.str.split(',').apply(lambda x: list(filter(lambda num: num != '', x)))\n",
    "        intervals_MS.veh_stop_lengths = intervals_MS.veh_stop_lengths.apply(lambda x: list(map(float,x)))\n",
    "        intervals_MS = intervals_MS.drop(['stop_type','new_type','stop_length','new_length'], axis=1)\n",
    "        print('Duration of calculating stops: ', (time.time()-start))\n",
    "    else:\n",
    "        intervals_MS['veh_stop_types'] = ['']*len(intervals_MS)\n",
    "        intervals_MS['veh_stop_lengths'] = ['']*len(intervals_MS)\n",
    "\n",
    "    # Lane Changes:\n",
    "    # Import the coordinates for the lanes from csv-files.\n",
    "    t = time.time()\n",
    "    lanes_coords = pd.read_csv('../data/%s_Lanes.csv'%polygon_name,sep=';')\n",
    "    lanes_df = pd.DataFrame(columns = ['lane_coords'])\n",
    "    for id_,lane in lanes_coords.iterrows():\n",
    "        lanes_df.loc[id_] = Polygon([[float(lane.OL.split(',')[1]),float(lane.OL.split(',')[0])],\n",
    "                                 [float(lane.OR.split(',')[1]),float(lane.OR.split(',')[0])],\n",
    "                                 [float(lane.UR.split(',')[1]),float(lane.UR.split(',')[0])],\n",
    "                                 [float(lane.UL.split(',')[1]),float(lane.UL.split(',')[0])]])\n",
    "\n",
    "    # Match the points on the link to the lanes, starting with lane 0 from the right most lane in driving direction\n",
    "    waypoints_w_dist_mode['lane_id'] = [-1]*len(waypoints_w_dist_mode)\n",
    "    for id_,lane_polygon in lanes_df.iterrows():\n",
    "        waypoints_w_dist_mode['lane_id'] = np.where(waypoints_w_dist_mode.geometry.within(lane_polygon['lane_coords']),\n",
    "                                                    id_,waypoints_w_dist_mode['lane_id'])\n",
    "    # Calculate lane changes\n",
    "    waypoints_w_dist_mode = waypoints_w_dist_mode[waypoints_w_dist_mode.lane_id>-1]\n",
    "    waypoints_w_dist_mode['lane_id_diff'] = waypoints_w_dist_mode.groupby('unique_id')['lane_id'].diff()\n",
    "    waypoints_w_dist_mode['lane_change'] = ((waypoints_w_dist_mode['lane_id_diff'] != 0) & (~(pd.isnull(waypoints_w_dist_mode['lane_id_diff']))))\n",
    "    \n",
    "    # Set lane changes per vehicle and interval\n",
    "    # Keep (for every vehicle) the first timestamp where the lane change was performed and remove motorcycles\n",
    "    l_c = waypoints_w_dist_mode[waypoints_w_dist_mode.lane_change]\n",
    "    l_c = l_c[l_c['type']!='Motorcycle'].groupby('unique_id').first()\n",
    "    \n",
    "    # Add the stops to the intervals\n",
    "    intervals_MS['lane_changes'] = np.zeros(len(intervals_MS))\n",
    "    # Add all columns that match the stop, vehicles type and duration to the intervals\n",
    "    for i,row in l_c.iterrows():\n",
    "        t_start_lower_timestamp = row['timestamp'] > (intervals_MS.times-pd.Timedelta('150s')) #1\n",
    "        t_end_higher_timestamp = row['timestamp'] < (intervals_MS.times+pd.Timedelta('30s')) #2\n",
    "        #1+2 must be true\n",
    "        true = (t_start_lower_timestamp & t_end_higher_timestamp)\n",
    "        # additionally add the vehicle type of that stop and the duration\n",
    "        intervals_MS.lane_changes += true\n",
    "    if save == 'on':\n",
    "        intervals_MS.to_pickle('../output/data_processed_events_%skmh_%ssec/processed_data_%s.pkl'%(min_mean_speed,min_duration_of_stops,polygon_name))\n",
    "    print('Calculation of stops and lane changes for %s done!'%polygon_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09a364",
   "metadata": {},
   "source": [
    "# Load and Merge Data together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea5dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_MS = pd.concat( [pd.read_pickle('../output/data_processed_events_%skmh_%ssec/processed_data_%s.pkl'%(min_mean_speed,min_duration_of_stops,p)) \n",
    "                     for p in polygon_names] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cb7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_MS.to_pickle('../output/data_processed_events_%skmh_%ssec/processed_data_all_bypolygon.pkl'%(min_mean_speed,min_duration_of_stops))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
