{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3741d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "import contextily as cx\n",
    "import datetime as dt\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "import haversine as hs\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcol\n",
    "\n",
    "from functions_file import *\n",
    "print(testfunction(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f03335",
   "metadata": {},
   "source": [
    "### Outline\n",
    "1. Prep\n",
    "2. Calculate Mobile Sensor values\n",
    "3. Make a loop detector and calculate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f594b63",
   "metadata": {},
   "source": [
    "### 1. Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af456b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# car penetration rates as modes: 5 %\n",
    "carmodes = ['Car0050'] \n",
    "# Assumed vehicle lengths:\n",
    "lengths = {'Car':5,'Bus':12.5,'Taxi':5,'Motorcycle':2.5,'Medium Vehicle':5.83,'Heavy Vehicle':12.5}\n",
    "DOW_exp_dict = [['Wed',[1,2,3,4,5]],['Mon',[6,7,9,10]],['Tue',[11,12,13,14,15]],['Thu',[17,18,19,20]]]\n",
    "polygons = pd.read_csv('../data/polygons11.csv')\n",
    "# Polygon 4 (road segment 4) is dropped, as it is a different kind of road segment; it is multiple blocks long. Polygons 0-3 and 5-11 are used (11 segments).\n",
    "polygons = polygons.drop([4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47419c6b",
   "metadata": {},
   "source": [
    "### 2. Process Mobile Sensor (MS) Data and calculate v, q, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc3dff6",
   "metadata": {},
   "source": [
    "The car modes ('cars') are calculated separately from all other considered modes ('regular') to account for the various penetration rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36eb3d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# CALCULATE VALUES - based on timestamp, for all polygons\n",
    "######################\n",
    "for version in ['regular','cars']: \n",
    "    save = 'off' # 'on' for saving the calculations\n",
    "    for polygon_name in polygons.name:\n",
    "        \n",
    "        # load data\n",
    "        waypoints_w_dist_mode,POLYGON = load_data(polygon_name,polygons)\n",
    "        # set time interval\n",
    "        step = dt.timedelta(seconds=30)\n",
    "        # select version\n",
    "        save_data = []\n",
    "        if 'cars'==version:\n",
    "            modes = carmodes\n",
    "            savefilename = '../output/data_flow/flow_data_MS_%s_cars.json'%(POLYGON['name'])\n",
    "        if 'regular'==version:\n",
    "            modes = np.append( waypoints_w_dist_mode['type'].unique(), ['all'])\n",
    "            savefilename = '../output/data_flow/flow_data_MS_%s.json'%(POLYGON['name'])\n",
    "\n",
    "        # 0. per mode\n",
    "        for mode in modes:\n",
    "\n",
    "            # 1. select data (the functions are in functions_file.py)\n",
    "            mode_section,_ = get_mode_section(mode,carmodes,waypoints_w_dist_mode,lengths)\n",
    "            if not len(mode_section)>0:\n",
    "                print('No data for ',mode)\n",
    "                continue\n",
    "            # 2. process each experiment\n",
    "            for DOW,day in DOW_exp_dict:\n",
    "\n",
    "                # regular version\n",
    "                '''for exp in day:\n",
    "                    exp_results = process_exp_MS_Edie([mode_section,mode,POLYGON,day,DOW,exp,step])\n",
    "                    if (exp_results is not None):\n",
    "                        save_data.append(exp_results)'''\n",
    "                # parallel version (no output)\n",
    "                t1 = dt.datetime.now()\n",
    "                print('Polygon: ',polygon_name,', length: ',POLYGON['length'])\n",
    "                day_results = Parallel(n_jobs=-2)(delayed(process_exp_MS_Edie)([mode_section,mode,POLYGON,day,DOW,exp,step]) for exp in day) \n",
    "                # save\n",
    "                print('Duration:',dt.datetime.now()-t1,'--> ',DOW,'done')\n",
    "                for exp_results in day_results:\n",
    "                    if (exp_results is not None):\n",
    "                        save_data.append(exp_results)\n",
    "\n",
    "        # 4. save data\n",
    "        if save=='on':\n",
    "            with open(savefilename, 'w', encoding='utf-8') as f: \n",
    "                json.dump(save_data, f, default=str)\n",
    "        save_data = pd.DataFrame(save_data,columns=['polygon','mode','day','DOW','exp_id','speeds','densities','flows','times'])\n",
    "        display(save_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361facc9",
   "metadata": {},
   "source": [
    "### 3. Generate LD Data and calculate v, q, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79636cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# SINGLE LOOP DETECTOR - only q and occ\n",
    "######################\n",
    "\n",
    "save = 'off' # 'on' for saving the calculations\n",
    "for polygon_name in polygons.name: \n",
    "    \n",
    "    waypoints_w_dist_mode,POLYGON = load_data(polygon_name,polygons,file_type='csv')\n",
    "\n",
    "    # set loop detector location\n",
    "    location = POLYGON['length']*1000-35 # LD approx. 30-40m from end of segment (signals)\n",
    "    # set time parameters\n",
    "    window = None      # --> hour: H, min: T, sec: s\n",
    "    resample = '30s'   # --> hour: H, min: T, sec: s\n",
    "    resampleInSec = 30 \n",
    "    timetohour = 3600/resampleInSec # resample*timetohour = 1hr\n",
    "    \n",
    "    # prep\n",
    "    cs = list(POLYGON['coords'].exterior.coords) # corners\n",
    "    save_data = []\n",
    "    modes = ['all'] # DON'T NEED ANY MODES EXCEPT FOR 'ALL'\n",
    "    savefilename = '../output/data_flow/flow_data_singleLD_%s_%s.json'%(POLYGON['name'],resample)\n",
    "    \n",
    "    # 0. per mode\n",
    "    for mode in modes: \n",
    "        \n",
    "        # 1. select data\n",
    "        mode_section,vehlength = get_mode_section(mode,carmodes,waypoints_w_dist_mode,lengths)\n",
    "        if not len(mode_section)>0:\n",
    "            print('No data for ',mode)\n",
    "            continue\n",
    "        \n",
    "        # 2. process each experiment\n",
    "        for DOW,day in DOW_exp_dict:\n",
    "            # regular version\n",
    "            '''for exp in day:\n",
    "                exp_results = process_exp_LD([mode_section,mode,POLYGON,day,DOW,exp,location,cs,vehlength,resample,resampleInSec,timetohour,window])\n",
    "                #if plot=='on':\n",
    "                #    plt.scatter(LD_info_.density,LD_info_.flow)\n",
    "                if (exp_results is not None):\n",
    "                    save_data.append(exp_results)'''\n",
    "                    \n",
    "            # parallel version\n",
    "            exp_results = Parallel(n_jobs=-2)(delayed(process_exp_LD)([mode_section,mode,POLYGON,day,DOW,exp,location,cs,vehlength,resample,resampleInSec,timetohour,window]) for exp in day) # -2 --> all but one proc\n",
    "            for exp in exp_results:\n",
    "                if (exp is not None):\n",
    "                    save_data.append(exp)\n",
    "\n",
    "    \n",
    "    # 3. save data\n",
    "    if save=='on':\n",
    "        with open(savefilename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(save_data, f, default=str)\n",
    "    save_data = pd.DataFrame(save_data,columns=['polygon','mode','day','DOW','exp_id','speeds','densities','flows','times'])\n",
    "    display(save_data.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
